// import { JSX, useState } from "react";
// import SpeechRecognition, {
//   useSpeechRecognition,
// } from "react-speech-recognition";

// // C·∫•u h√¨nh API base URL
// const API_BASE_URL = "http://localhost:8000";

// function Pronunciation() {
//   const [conversations, setConversations] = useState<JSX.Element[]>([]);
//   const [loading, setLoading] = useState(false);
//   const [audioLoading, setAudioLoading] = useState(false);
//   const [selectedTopic, setSelectedTopic] = useState<string>("Ordering Food"); // Gi√° tr·ªã m·∫∑c ƒë·ªãnh l√† "Ordering Food"
//   const {
//     transcript,
//     listening,
//     resetTranscript,
//     browserSupportsSpeechRecognition,
//   } = useSpeechRecognition();

//   const startRecognition = () => {
//     if (!browserSupportsSpeechRecognition) {
//       setConversations((prev) => [
//         ...prev,
//         <p key={prev.length}>Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ nh·∫≠n di·ªán gi·ªçng n√≥i.</p>,
//       ]);
//       return;
//     }

//     resetTranscript();
//     SpeechRecognition.startListening({ language: "en-US", continuous: false });
//   };

//   const stopRecognition = () => {
//     SpeechRecognition.stopListening();
//     if (transcript) {
//       handleSendRequest(transcript);
//     }
//   };

//   const handleSendRequest = async (text: string) => {
//     setLoading(true);
//     try {
//       console.log("G·ª≠i vƒÉn b·∫£n l√™n server:", text);
//       const res = await fetch(`${API_BASE_URL}/text-and-respond/`, {
//         method: "POST",
//         headers: {
//           "Content-Type": "application/json",
//         },
//         body: JSON.stringify({ user_text: text, topic: selectedTopic }),
//       });

//       if (!res.ok) throw new Error(`Y√™u c·∫ßu th·∫•t b·∫°i v·ªõi m√£ ${res.status}`);

//       const data = await res.json();
//       console.log("Ph·∫£n h·ªìi t·ª´ API:", data);
//       const newConversation = (
//         <p key={conversations.length}>
//           üßë B·∫°n: {data.user_text}
//           <br />
//           ü§ñ AI: {data.ai_response}
//         </p>
//       );
//       setConversations((prev) => [...prev, newConversation]);

//       if (data.audio_url) {
//         setAudioLoading(true);
//         const audio = new Audio(`${API_BASE_URL}${data.audio_url}`);
//         audio.onloadeddata = () => {
//           console.log("√Çm thanh ƒë√£ t·∫£i th√†nh c√¥ng.");
//           setAudioLoading(false);
//         };
//         audio.onended = () => {
//           setConversations((prev) => [
//             ...prev,
//             <p key={prev.length}>√Çm thanh ƒë√£ ph√°t th√†nh c√¥ng.</p>,
//           ]);
//         };
//         audio.onerror = (event: any) => {
//           console.error("L·ªói ph√°t √¢m thanh:", event);
//           setConversations((prev) => [
//             ...prev,
//             <p key={prev.length}>
//               L·ªói ph√°t √¢m thanh: {event.message || "Kh√¥ng x√°c ƒë·ªãnh"}
//             </p>,
//           ]);
//           setAudioLoading(false);
//         };
//         audio.play().catch((err) => {
//           console.error("L·ªói khi ph√°t √¢m thanh:", err);
//           setConversations((prev) => [
//             ...prev,
//             <p key={prev.length}>L·ªói ph√°t √¢m thanh: {err.message}</p>,
//           ]);
//           setAudioLoading(false);
//         });
//       }
//     } catch (err: any) {
//       console.error("L·ªói g·ª≠i y√™u c·∫ßu:", err);
//       setConversations((prev) => [
//         ...prev,
//         <p key={prev.length}>C√≥ l·ªói khi g·ª≠i y√™u c·∫ßu API: {err.message}</p>,
//       ]);
//     } finally {
//       setLoading(false);
//     }
//   };

//   return (
//     <div className="min-h-screen bg-gray-100 p-4">
//       <h2 className="text-2xl font-bold mb-4 text-center">
//         G·ªçi tr·ª£ l√Ω h·ªçc ti·∫øng Anh
//       </h2>

//       {/* Dropdown ch·ªçn ch·ªß ƒë·ªÅ */}
//       <div className="mb-4">
//         <label htmlFor="topic" className="block text-lg mb-2">
//           Ch·ªçn ch·ªß ƒë·ªÅ:
//         </label>
//         <select
//           id="topic"
//           className="p-2 border rounded"
//           value={selectedTopic}
//           onChange={(e) => setSelectedTopic(e.target.value)}
//         >
//           <option value="Ordering Food">ƒê·∫∑t m√≥n ƒÉn</option>
//           <option value="Travelling">Du l·ªãch</option>
//           <option value="Shopping">Mua s·∫Øm</option>
//           <option value="Daily Conversation">Giao ti·∫øp h√†ng ng√†y</option>
//         </select>
//       </div>

//       <div className="flex space-x-4 mb-4">
//         <button
//           onClick={startRecognition}
//           disabled={listening || loading}
//           className="px-4 py-2 bg-blue-500 text-white rounded disabled:bg-blue-300"
//         >
//           {listening ? "ƒêang nh·∫≠n di·ªán..." : "B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán"}
//         </button>
//         <button
//           onClick={stopRecognition}
//           disabled={!listening || loading}
//           className="px-4 py-2 bg-red-500 text-white rounded disabled:bg-red-300"
//         >
//           D·ª´ng nh·∫≠n di·ªán
//         </button>
//       </div>
//       <div className="mb-4">
//         <p className="text-gray-700">
//           VƒÉn b·∫£n nh·∫≠n di·ªán: {transcript || "Ch∆∞a c√≥ d·ªØ li·ªáu"}
//         </p>
//       </div>
//       <div
//         className="h-full bg-white p-4 rounded shadow-md overflow-y-auto"
//         style={{ maxHeight: "60vh" }}
//       >
//         {conversations.map((conv, index) => (
//           <div key={index} className="mb-2">
//             {conv}
//           </div>
//         ))}
//       </div>
//       {loading && (
//         <p className="mt-2 text-center text-gray-600">ƒêang x·ª≠ l√Ω...</p>
//       )}
//       {audioLoading && (
//         <p className="mt-2 text-center text-gray-600">ƒêang t·∫£i √¢m thanh...</p>
//       )}
//     </div>
//   );
// }

// export default Pronunciation;

import { JSX, useState } from "react";
import SpeechRecognition, {
  useSpeechRecognition,
} from "react-speech-recognition";

// C·∫•u h√¨nh API base URL
const API_BASE_URL = "http://localhost:8000";

// Danh s√°ch ng√¥n ng·ªØ h·ªó tr·ª£
const LANGUAGE_MAP = {
  en: { name: "English", speechLang: "en-US" },
  vi: { name: "Vietnamese", speechLang: "vi-VN" },
  ja: { name: "Japanese", speechLang: "ja-JP" },
  ko: { name: "Korean", speechLang: "ko-KR" },
  zh: { name: "Chinese", speechLang: "zh-CN" },
};

// Danh s√°ch ch·ªß ƒë·ªÅ
const TOPICS = [
  { value: "restaurant", label: "Restaurant" },
  { value: "market", label: "Market" },
  { value: "hospital", label: "Hospital" },
];

function Pronunciation() {
  const [conversations, setConversations] = useState<JSX.Element[]>([]);
  const [loading, setLoading] = useState(false);
  const [audioLoading, setAudioLoading] = useState(false);
  const [selectedTopic, setSelectedTopic] = useState<string>("restaurant");
  const [selectedLanguage, setSelectedLanguage] = useState<string>("en");
  const {
    transcript,
    listening,
    resetTranscript,
    browserSupportsSpeechRecognition,
  } = useSpeechRecognition();

  const startRecognition = () => {
    if (!browserSupportsSpeechRecognition) {
      setConversations((prev) => [
        ...prev,
        <p key={prev.length}>Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ nh·∫≠n di·ªán gi·ªçng n√≥i.</p>,
      ]);
      return;
    }

    resetTranscript();
    console.log(
      "Starting speech recognition with language:",
      LANGUAGE_MAP[selectedLanguage].speechLang
    );
    SpeechRecognition.startListening({
      language: LANGUAGE_MAP[selectedLanguage].speechLang,
      continuous: false,
    });
  };

  const stopRecognition = () => {
    SpeechRecognition.stopListening();
    console.log("Transcript:", transcript);
    if (transcript) {
      console.log("Calling handleSendRequest with:", transcript);
      handleSendRequest(transcript);
    } else {
      console.log("No transcript, skipping API call");
      setConversations((prev) => [
        ...prev,
        <p key={prev.length}>
          Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c gi·ªçng n√≥i, vui l√≤ng th·ª≠ l·∫°i.
        </p>,
      ]);
    }
  };

  const handleSendRequest = async (text: string) => {
    setLoading(true);
    try {
      console.log("Sending request to API:", {
        user_text: text,
        topic: selectedTopic,
        language: selectedLanguage,
      });
      const res = await fetch(`${API_BASE_URL}/text-and-respond/`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          user_text: text,
          topic: selectedTopic,
          language: selectedLanguage,
        }),
      });

      if (!res.ok) {
        const errorData = await res.json();
        throw new Error(
          `Y√™u c·∫ßu th·∫•t b·∫°i v·ªõi m√£ ${res.status}: ${JSON.stringify(errorData)}`
        );
      }

      const data = await res.json();
      console.log("API response:", data);
      const newConversation = (
        <p key={conversations.length}>
          üßë B·∫°n: {data.user_text}
          <br />
          ü§ñ Amma: {data.ai_response}
        </p>
      );
      setConversations((prev) => [...prev, newConversation]);

      if (data.audio_url) {
        setAudioLoading(true);
        const audio = new Audio(`${API_BASE_URL}${data.audio_url}`);
        audio.onloadeddata = () => {
          console.log("Audio loaded successfully.");
          setAudioLoading(false);
        };
        audio.onended = () => {
          setConversations((prev) => [
            ...prev,
            <p key={prev.length}>√Çm thanh ƒë√£ ph√°t th√†nh c√¥ng.</p>,
          ]);
        };
        audio.onerror = (event: any) => {
          console.error("Audio playback error:", event);
          setConversations((prev) => [
            ...prev,
            <p key={prev.length}>
              L·ªói ph√°t √¢m thanh: {event.message || "Kh√¥ng x√°c ƒë·ªãnh"}
            </p>,
          ]);
          setAudioLoading(false);
        };
        audio.play().catch((err) => {
          console.error("Error playing audio:", err);
          setConversations((prev) => [
            ...prev,
            <p key={prev.length}>L·ªói ph√°t √¢m thanh: {err.message}</p>,
          ]);
          setAudioLoading(false);
        });
      }
    } catch (err: any) {
      console.error("Error sending request:", err);
      setConversations((prev) => [
        ...prev,
        <p key={prev.length}>C√≥ l·ªói khi g·ª≠i y√™u c·∫ßu API: {err.message}</p>,
      ]);
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="min-h-screen bg-gray-100 p-4">
      <h2 className="text-2xl font-bold mb-4 text-center">
        G·ªçi tr·ª£ l√Ω h·ªçc ng√¥n ng·ªØ - Amma
      </h2>

      {/* Dropdown ch·ªçn ng√¥n ng·ªØ */}
      <div className="mb-4">
        <label htmlFor="language" className="block text-lg mb-2">
          Ch·ªçn ng√¥n ng·ªØ:
        </label>
        <select
          id="language"
          className="p-2 border rounded w-full"
          value={selectedLanguage}
          onChange={(e) => setSelectedLanguage(e.target.value)}
        >
          {Object.entries(LANGUAGE_MAP).map(([code, { name }]) => (
            <option key={code} value={code}>
              {name}
            </option>
          ))}
        </select>
      </div>

      {/* Dropdown ch·ªçn ch·ªß ƒë·ªÅ */}
      <div className="mb-4">
        <label htmlFor="topic" className="block text-lg mb-2">
          Ch·ªçn ch·ªß ƒë·ªÅ:
        </label>
        <select
          id="topic"
          className="p-2 border rounded w-full"
          value={selectedTopic}
          onChange={(e) => setSelectedTopic(e.target.value)}
        >
          {TOPICS.map(({ value, label }) => (
            <option key={value} value={value}>
              {label}
            </option>
          ))}
        </select>
      </div>

      <div className="flex space-x-4 mb-4">
        <button
          onClick={startRecognition}
          disabled={listening || loading}
          className="px-4 py-2 bg-blue-500 text-white rounded disabled:bg-blue-300"
        >
          {listening ? "ƒêang nh·∫≠n di·ªán..." : "B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán"}
        </button>
        <button
          onClick={stopRecognition}
          disabled={!listening || loading}
          className="px-4 py-2 bg-red-500 text-white rounded disabled:bg-red-300"
        >
          D·ª´ng nh·∫≠n di·ªán
        </button>
        <button
          onClick={() => handleSendRequest("Test API call")}
          disabled={loading}
          className="px-4 py-2 bg-green-500 text-white rounded disabled:bg-green-300"
        >
          Th·ª≠ API
        </button>
      </div>
      <div className="mb-4">
        <p className="text-gray-700">
          VƒÉn b·∫£n nh·∫≠n di·ªán: {transcript || "Ch∆∞a c√≥ d·ªØ li·ªáu"}
        </p>
      </div>
      <div
        className="h-full bg-white p-4 pb-20 rounded shadow-md overflow-y-auto"
        style={{ maxHeight: "60vh" }}
      >
        {conversations.map((conv, index) => (
          <div key={index} className="mb-2">
            {conv}
          </div>
        ))}
      </div>
      {loading && (
        <p className="mt-2 text-center text-gray-600">ƒêang x·ª≠ l√Ω...</p>
      )}
      {audioLoading && (
        <p className="mt-2 text-center text-gray-600">ƒêang t·∫£i √¢m thanh...</p>
      )}
    </div>
  );
}

export default Pronunciation;
